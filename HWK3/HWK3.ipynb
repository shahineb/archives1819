{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-notebook')\n",
    "plot_kwds = {'alpha': 0.5, 's': 80, 'linewidths': 0}\n",
    "from utils.KMeans import KMeans\n",
    "from utils.GaussianMixtureModel import GaussianMixtureModel, FIGSIZE, MARKER, MARKER_COLOR, CMAP, MARKER_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load datasets__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning set :  (500, 2)\n",
      "Testing set :  (500, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_table(\"data/EMGaussian.data\", sep=\" \", header=None)\n",
    "test = pd.read_table(\"data/EMGaussian.test\", sep=\" \", header=None)\n",
    "\n",
    "n_sample_train, n_feature = train.shape\n",
    "n_sample_test = test.shape[0]\n",
    "\n",
    "print \"Traning set : \", train.shape\n",
    "print \"Testing set : \", test.shape\n",
    "\n",
    "train = train.values\n",
    "test = test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\alpha$ and $\\beta$ recursion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM on HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ALPHA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-21e2cc96908b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mmyHMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialization\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \"\"\"\n\u001b[1;32m      5\u001b[0m         \u001b[0mAttributes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-21e2cc96908b>\u001b[0m in \u001b[0;36mmyHMM\u001b[0;34m()\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mplot_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_kwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFIGSIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCMAP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mALPHA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mQUANTILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \"\"\"plots labeled data, centroids and confidence interval ellipses\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ALPHA' is not defined"
     ]
    }
   ],
   "source": [
    "class myHMM(object):\n",
    "\n",
    "    def __init__(self, k, initialization):\n",
    "        \"\"\"\n",
    "        Attributes:\n",
    "        -----------\n",
    "        k_: integer\n",
    "            number of components\n",
    "        initialization_: {\"kmeans\", \"random\"}\n",
    "            type of initialization\n",
    "        N_: numpy.array\n",
    "            (nr_sample, k_)\n",
    "            matrix of gaussian pdf evaluation on each sample for each\n",
    "            distribution\n",
    "        pi0_: numpy.array\n",
    "            (k_,)\n",
    "            multinomial law vector for first node\n",
    "        A_: numpy.array\n",
    "            (k_, k_)\n",
    "            transition probability matrix\n",
    "        mu_: numpy.array\n",
    "            (k_, nr_feature)\n",
    "            array containing means\n",
    "        Sigma_: numpy.array\n",
    "            (k_, nr_feature, nr_feature)\n",
    "            array containing covariance matrix\n",
    "        alpha_: numpy.array\n",
    "            (nr_sample,)   #############\n",
    "            alpha messages\n",
    "        beta_: numpy.array\n",
    "            (nr_sample,)        #######################\n",
    "            beta messages\n",
    "        cond_prob_: numpy.array\n",
    "            (nr_sample, k_)\n",
    "            probability matrix of latent variables given observed variables\n",
    "        cond_prob_bis_: numpy.array\n",
    "            (nr_sample - 1, k_ , k_)\n",
    "            probability matrix of two successive latent variables given observed variables \n",
    "        \"\"\"\n",
    "        self.k_ = k\n",
    "        self.initialization_ = initialization\n",
    "        self.N_ = None\n",
    "        self.pi0_ = None\n",
    "        self.A_ = None\n",
    "        self.mu_ = None\n",
    "        self.Sigma_ = None\n",
    "        self.alpha_ = None\n",
    "        self.beta_ = None\n",
    "        self.cond_prob_ = None\n",
    "        self.cond_prob_bis_ = None\n",
    "\n",
    "    @property\n",
    "    def nr_sample(self):\n",
    "        return len(mu_)\n",
    "    \n",
    "    def compute_multivariate_normal_matrix(self, X):\n",
    "        \"\"\"Computes the matrix of gaussian pdf evaluation on each sample for each\n",
    "            distribution\n",
    "        \"\"\"\n",
    "        self.N_ = np.array([stats.multivariate_normal(self.mu_[k], self.Sigma_[k]).pdf(X) for k in range(self.k_)]).T\n",
    "    \n",
    "    \n",
    "    def compute_messages(self, X):\n",
    "        \"\"\"Computes alpha and beta messages, stored as log for computation issues\n",
    "        \"\"\"\n",
    "        \n",
    "        alpha = np.zeros((self.nr_sample,self.k))\n",
    "        \n",
    "        #alpha for the initial states\n",
    "        alpha[0] = np.log(self.pi0_) + np.log(self.N_[:, 0])\n",
    "        \n",
    "        #alpha for all the other states\n",
    "        for t in range(self.nr_sample):\n",
    "            va = np.log(A_) + alpha[t-1]\n",
    "            max_va =  np.max(va, axis=1)\n",
    "            alpha[t] = np.log(self.N_[:,t]) + max_va + np.log(np.sum(np.exp(va - max_va[:, np.newaxis]), axis=1))\n",
    "        \n",
    "        self.alpha_ = alpha\n",
    "        \n",
    "        #################################################\n",
    "        \n",
    "        beta = np.zeros((self.nr_sample,self.k_))\n",
    "        \n",
    "        #beta for the initial states\n",
    "        beta[-1] = np.zeros(self.k_) #useless after the initialization\n",
    "        \n",
    "        #beta for all the other states\n",
    "        for t in range(self.nr_sample-2, -1, -1):\n",
    "            va = np.log(A_) + beta[t+1] + np.log(self.N_[:,t+1])\n",
    "            max_va = np.max(va,axis=1)\n",
    "            beta[t] = max_va + np.log(np.sum(np.exp(va - max_va[:, np.newaxis]), axis=1))\n",
    "        \n",
    "        self.beta_ = beta\n",
    "            \n",
    "        \n",
    "    def compute_condition_prob_matrix_(self, X):\n",
    "        '''Compute the conditional probability matrix cond_prob_ and cond_prob_bis_\n",
    "        '''\n",
    "        \n",
    "        maxi = np.max(self.alpha_ + self.beta_, axis=0)\n",
    "        proba_y = np.exp(maxi)*np.sum(np.exp(self.alpha_*self.beta_-maxi))\n",
    "\n",
    "        self.cond_prob_ = np.exp(self.alpha_)*np.exp(self.beta_)/proba_y\n",
    "        \n",
    "        ##########################################\n",
    "        \n",
    "        for t in range(self.nr_sample-1):\n",
    "            for i in range(self.k_):\n",
    "                va = np.full(self.alpha_[t,i],self.k_) + self.beta_[t+1] + np.log(self.A_) + np.log(N[:,t+1])\n",
    "                self.cond_prob_bis_[t,i,:] = np.exp(va/proba_y)\n",
    "        \n",
    "\n",
    "    def compute_expectation_(self):\n",
    "        '''Compute the expectation to check increment'''\n",
    "        foo1 = np.inner(self.cond_prob_[0], np.log(self.pi0_))\n",
    "        foo2 = np.sum(np.log(self.A_) * np.sum(self.cond_prob_bis_, axis=0))\n",
    "        foo3 = np.sum(np.log(self.N_) * self.cond_prob_)\n",
    "        E_log_likelihood = foo1 + foo2 + foo3\n",
    "        return E_log_likelihood\n",
    "\n",
    "    def compute_estimators_(self, X):\n",
    "        '''Compute the MLE of the model parameters'''\n",
    "        self.pi0_ = self.cond_prob_[0] / np.sum(self.cond_prob_[0])\n",
    "        self.mu_ = [np.sum(X.T * self.cond_prob_[:, j], axis=1) / np.sum(self.cond_prob_[:, j]) for j in range(self.k_)]\n",
    "        self.Sigma_ = []\n",
    "        for j in range(self.k_):\n",
    "            foo = np.array([tau * np.matmul((x - self.mu_[j]).reshape(-1, 1), (x - self.mu_[j]).reshape(1, -1))\n",
    "                            for tau, x in zip(self.cond_prob_[:, j], X)])\n",
    "            foo = np.sum(foo, axis=0) / np.sum(self.cond_prob_[:, j])\n",
    "            self.Sigma_ += [foo]\n",
    "        self.A_ = np.sum(self.cond_prob_bis_, axis=0) / np.sum(self.cond_prob_[1:], axis=0)\n",
    "        \n",
    "    def initialize_(self, X):\n",
    "        gmm = GaussianMixtureModel(k=self.k_, initialization=self.initialization_)\n",
    "        gmm.fit(X)\n",
    "        self.mu_ = gmm.mu_\n",
    "        self.Sigma_ = gmm.Sigma_\n",
    "        \n",
    "        self.compute_messages(X)\n",
    "        self.compute_condition_prob_matrix_(X)\n",
    "        self.A_ = np.sum(self.cond_prob_bis_, axis=0) / np.sum(self.cond_prob_[1:], axis=0)\n",
    "\n",
    "    def fit(self, X, eps=1e-6, max_iter=1000):\n",
    "        \"\"\" Find the parameters pi_, mu_ and nu_\n",
    "        that better fit the data\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: (n, p) np.array\n",
    "            Data matrix\n",
    "\n",
    "        Returns:\n",
    "        -----\n",
    "        self\n",
    "        \"\"\"\n",
    "        # intialize\n",
    "        self.initialize_(X)\n",
    "        self.compute_estimators_(X)\n",
    "\n",
    "        n_iter = 0\n",
    "        l_c = 0\n",
    "        conv_criteria = True\n",
    "\n",
    "        while conv_criteria and n_iter < max_iter:\n",
    "            conv_criteria = l_c\n",
    "\n",
    "            self.compute_condition_prob_matrix_(X)\n",
    "            l_c = self.compute_expectation_()\n",
    "            self.compute_estimators_(X)\n",
    "\n",
    "            conv_criteria = np.abs(conv_criteria - l_c) < eps\n",
    "\n",
    "        self.labels_ = np.argmax(self.cond_prob_, axis=1)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\" Predict probability vector for X\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: (n, p) np.array\n",
    "\n",
    "        Returns:\n",
    "        -----\n",
    "        proba: (n, k) np.array\n",
    "        \"\"\"\n",
    "        n, p = X.shape\n",
    "        N_ = np.array([stats.multivariate_normal(self.mu_[k], self.Sigma_[k]).pdf(X) for k in range(self.k_)]).T\n",
    "        cond_prob_ = N_ * self.pi_\n",
    "        for i in range(n):\n",
    "            cond_prob_[i, :] = cond_prob_[i, :] / np.sum(cond_prob_[i, :])\n",
    "        return cond_prob_\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict labels for X\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: numpy.array\n",
    "            (nr_sample, nr_feature)\n",
    "        Returns:\n",
    "        -----\n",
    "        label affectation\n",
    "        \"\"\"\n",
    "        proba_cluster = self.predict_proba(X)\n",
    "        labels = np.argmax(proba_cluster, axis=1)\n",
    "        return labels\n",
    "\n",
    "\n",
    "    def plot_pred(self, X, labels, title, plot_kwds, ax=None, figsize=FIGSIZE, cmap=CMAP, alpha=ALPHA, quantile=QUANTILE):\n",
    "        \"\"\"plots labeled data, centroids and confidence interval ellipses\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array\n",
    "            (nr_sample, nr_feature)\n",
    "        title : str\n",
    "            figure title\n",
    "        level : float\n",
    "            level for confidence interval, must be between 0 and 1\n",
    "        ax : Axe\n",
    "        figsize : tuple\n",
    "        cmap : plt.cm\n",
    "            discrete colormap to be used for labeling\n",
    "        alpha : float\n",
    "            max opacity level for ellipses\n",
    "        quantile : float (>0 and <1)\n",
    "            level for confidence interval, must be between 0 and 1\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        def gen_cmap(rgb_color, max_opacity):\n",
    "            \"\"\"Generates single-color cmap with decreasing opacity\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            rgb_color : tuple\n",
    "                rgb color to use\n",
    "            max_opacity : float\n",
    "                highest level of opacity allowed\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            plt.cm\n",
    "                color map\n",
    "            \"\"\"\n",
    "            cdict = {'red': ((0., rgb_color[0], rgb_color[0]),\n",
    "                             (1., rgb_color[0], rgb_color[0])),\n",
    "                     'green': ((0., rgb_color[1], rgb_color[1]),\n",
    "                               (1., rgb_color[1], rgb_color[1])),\n",
    "                     'blue': ((0., rgb_color[2], rgb_color[2]),\n",
    "                              (1., rgb_color[2], rgb_color[2])),\n",
    "                     'alpha': ((0., max_opacity, max_opacity),\n",
    "                               (1., 0.05, 0.05))\n",
    "                     }\n",
    "            cmap = LinearSegmentedColormap('my_cmap', cdict)\n",
    "            return cmap\n",
    "\n",
    "        if not ax:\n",
    "            fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "        # Set title\n",
    "        ax.set_title(title, size=21)\n",
    "\n",
    "        # Plot labeled data\n",
    "        ax.grid(alpha=0.2)\n",
    "        ax.scatter(*X.T, c=labels, cmap=cmap, **plot_kwds)\n",
    "\n",
    "        # Retrieve colors used from cmap to plot labeled data\n",
    "        len_cmap = len(cmap.colors)\n",
    "        used_colors_idx = np.rint(np.linspace(0, len_cmap - 1, self.k_)).astype(int)\n",
    "\n",
    "        # Create meshgrid for ellipse plotting\n",
    "        x1_axis = np.linspace(*ax.get_xlim())\n",
    "        x2_axis = np.linspace(*ax.get_ylim())\n",
    "        granularity = len(x1_axis)\n",
    "        x1_grid, x2_grid = np.meshgrid(x1_axis, x2_axis)\n",
    "        x_1_2 = np.vstack([x1_grid.reshape(-1), x2_grid.reshape(-1)]).T\n",
    "\n",
    "        for j in range(self.k_):\n",
    "            # Add centroid\n",
    "            ax.scatter(*self.mu_[j], marker=MARKER, s=MARKER_SIZE, color=MARKER_COLOR)\n",
    "\n",
    "            # Compute ellipse equation\n",
    "            inv_sigma = np.linalg.inv(self.Sigma_[j])\n",
    "            z = np.diagonal(np.matmul(x_1_2 - self.mu_[j], np.matmul(inv_sigma, (x_1_2 - self.mu_[j]).T)))\n",
    "            z = z.reshape(granularity, granularity)\n",
    "\n",
    "            # Plot\n",
    "            level = stats.chi2.ppf(q=quantile, df=len(self.mu_[j]))\n",
    "            cluster_cmap = gen_cmap(cmap.colors[used_colors_idx[j]], max_opacity=alpha)\n",
    "            ax.contourf(x1_axis, x2_axis, z, levels=np.linspace(0, level, 10), cmap=cluster_cmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
